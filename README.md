# ğŸ¥ğŸ“š Lecture Video Embedding & Retrieval System

This project processes YouTube lecture videos and enables semantic and lexical search across video frames and transcript segments using embedding models like **CLIP** and **BGE**.

---

## ğŸ”§ Features

- âœ… Download and process YouTube videos.
- ğŸ–¼ï¸ Extract video frames and embed them using OpenAIâ€™s CLIP.
- ğŸ“ Transcribe videos using OpenAI Whisper and embed text chunks using BAAIâ€™s BGE.
- ğŸ“¦ Store embeddings in PostgreSQL with `pgvector`.
- ğŸ” Enable multimodal search: find frames and text semantically similar to a query.
- ğŸ”„ Integrate with BM25, TF-IDF, FAISS, and other retrieval methods (via Streamlit app, WIP).

---

## ğŸ“ Project Structure

```bash
.
â”œâ”€â”€ download_video.py          # Downloads video and generates transcript
â”œâ”€â”€ extract_frames.py          # Extracts frames from video (not shown here)
â”œâ”€â”€ embed_frames.py            # Embeds video frames using CLIP
â”œâ”€â”€ embed_text.py              # Embeds transcript segments using BGE
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ video.mp4
â”‚   â”œâ”€â”€ transcript.json
â”‚   â”œâ”€â”€ time_stamps.json
â”‚   â””â”€â”€ (frame images, if needed)
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ clip_frame_embeddings.npy
â”‚   â””â”€â”€ bge_text_embeddings.npy
â”œâ”€â”€ app/                       # Streamlit app (optional)
â””â”€â”€ README.md

bash'''

ğŸ§® PostgreSQL Integration

You can load the embeddings into a PostgreSQL database with pgvector for efficient similarity search.
'''sql
CREATE TABLE clip_frames (
    id SERIAL PRIMARY KEY,
    timestamp FLOAT,
    image_path TEXT,
    embedding VECTOR(512)
);

CREATE TABLE text_segments (
    id SERIAL PRIMARY KEY,
    start_time FLOAT,
    end_time FLOAT,
    text TEXT,
    embedding VECTOR(768)
);
sql'''
